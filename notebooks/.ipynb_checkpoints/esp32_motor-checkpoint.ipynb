{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ccfde09-b2d4-424c-a981-0b206c6e3f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import random as rn\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1fa494-d490-409e-b303-28c4a73247a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1379 images belonging to 2 classes.\n",
      "Found 343 images belonging to 2 classes.\n",
      "Wall time: 66 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_path = r\"../datasets/esp32_motor/training\"\n",
    "validation_path = r\"../datasets/esp32_motor/validation\"\n",
    "\n",
    "datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=[0.9, 1.1],\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rotation_range=10,\n",
    "    brightness_range=[1,0.6],\n",
    "    channel_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    ")\n",
    "train_generator=datagen.flow_from_directory(\n",
    "    directory=training_path, \n",
    "    color_mode='rgb', \n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    target_size=(320,480), \n",
    "    batch_size=32\n",
    ")\n",
    "validation_generator=datagen.flow_from_directory(\n",
    "    directory=validation_path, \n",
    "    color_mode='rgb', \n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    target_size=(320,480), \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df2a8ee-602d-4981-aff9-4ad54d7f160b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(0, 831), (1, 548)])\n",
      "dict_items([(0, 207), (1, 136)])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(train_generator.classes)\n",
    "print(counter.items())\n",
    "\n",
    "counter = Counter(validation_generator.classes)\n",
    "print(counter.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0ceda4-12c5-47be-89ba-4a054ecc488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# columns = 3\n",
    "# rows = 3\n",
    "\n",
    "# for i in range(1, columns*rows +1):    \n",
    "#     img, label = train_generator.next()\n",
    "#     ax = fig.add_subplot(rows, columns, i)\n",
    "#     plt.imshow((img[0] * 255).astype(np.uint8))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab479782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# columns = 3\n",
    "# rows = 3\n",
    "\n",
    "# for i in range(1, columns*rows +1):    \n",
    "#     img, label = validation_generator.next()\n",
    "#     fig.add_subplot(rows, columns, i)\n",
    "#     plt.imshow((img[0] * 255).astype(np.uint8))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa890b7-716e-4b39-ae47-d30167f9fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top=False, \n",
    "                   weights='imagenet', \n",
    "                   input_shape=(320,480,3), \n",
    "                   pooling=None)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54f2cfe-8e76-4ed1-8dc2-ec8a903af9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 320, 480, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 320, 480, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 320, 480, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 160, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 160, 240, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 160, 240, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 80, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 80, 120, 256)      295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 80, 120, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 80, 120, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 40, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 40, 60, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 40, 60, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 40, 60, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 20, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 20, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 20, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 20, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 10, 15, 512)       0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b8dc3f-c0b5-4f3f-8053-c3a9a6c39e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 10, 15, 512)       14714688  \n",
      "_________________________________________________________________\n",
      "Cust_Conv1 (Conv2D)          (None, 8, 13, 32)         147488    \n",
      "_________________________________________________________________\n",
      "Cust_Pool1 (MaxPooling2D)    (None, 4, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "Cust_FC1 (Dense)             (None, 128)               98432     \n",
      "_________________________________________________________________\n",
      "Cust_FC2 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 14,968,994\n",
      "Trainable params: 254,306\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cust_model = Sequential()\n",
    "cust_model.add(base_model)\n",
    "cust_model.add(Conv2D(filters=32,\n",
    "                      kernel_size=(3,3),\n",
    "                      strides=(1,1),\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=tf.keras.initializers.he_normal(seed=0),\n",
    "                      name='Cust_Conv1'))\n",
    "cust_model.add(MaxPool2D(pool_size=(2,2),\n",
    "                         strides=(2,2),\n",
    "                         name='Cust_Pool1'))\n",
    "cust_model.add(Flatten())\n",
    "cust_model.add(Dense(units=128,\n",
    "                     activation='relu',\n",
    "                     kernel_initializer=tf.keras.initializers.glorot_normal(seed=32),\n",
    "                     name='Cust_FC1'))\n",
    "cust_model.add(Dense(units=64,\n",
    "                     activation='relu',\n",
    "                     kernel_initializer=tf.keras.initializers.glorot_normal(seed=33),\n",
    "                     name='Cust_FC2'))\n",
    "\n",
    "cust_model.add(Dropout(0.2))\n",
    "\n",
    "cust_model.add(Flatten())\n",
    "\n",
    "# cust_model.add(Flatten())\n",
    "# cust_model.add(Dense(50, activation='relu'))\n",
    "# cust_model.add(Dense(10, activation='relu'))\n",
    "\n",
    "cust_model.add(Dense(units=2,\n",
    "                     activation='sigmoid',\n",
    "                     kernel_initializer=tf.keras.initializers.glorot_normal(seed=3),\n",
    "                     name='Output'))\n",
    "print(cust_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f54591ec-35c1-42ee-aaeb-4ac0a7968af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                   loss='categorical_crossentropy',                 \n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ce569ae-4262-4087-bd79-d2ffa041d695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "print(STEP_SIZE_TRAIN)\n",
    "print(STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8c7ce-ee30-4b4e-980a-6240856efb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/43 [==============================] - 97s 2s/step - loss: 0.5539 - accuracy: 0.7476 - val_loss: 0.3356 - val_accuracy: 0.9281\n",
      "Epoch 2/5\n",
      " 8/43 [====>.........................] - ETA: 53s - loss: 0.3195 - accuracy: 0.9375"
     ]
    }
   ],
   "source": [
    "history = cust_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = STEP_SIZE_VALID,\n",
    "    epochs = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860365f-c95d-4207-83cd-e21ef37c2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = r\"../datasets/esp32_motor/test\"\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_generator=test_datagen.flow_from_directory(\n",
    "    directory=path_test, \n",
    "    color_mode = 'rgb', \n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    target_size=(320,480), \n",
    "    batch_size=1,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a188271f-586c-4d58-b178-6627defe6389",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(test_generator.classes)\n",
    "print(counter.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05efbf5-9279-40ae-83af-25c833f7ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "columns = 3\n",
    "rows = 3\n",
    "\n",
    "for i in range(1, columns*rows +1):    \n",
    "    img, label = test_generator.next()\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow((img[0] * 255).astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5181d-3d3d-4613-aae0-e16858f593d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "STEP_SIZE_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322cbf42-1c26-4099-8ec8-bafc8dcbb092",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_model.evaluate(test_generator,\n",
    "steps=STEP_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6560bfb-3f68-4e1f-b024-ab55ef066f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_model.save(\"model_esp32_motor.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01c0413-b017-43a9-9088-425a74370cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c424d-22f1-4ae9-a24e-71b07487f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)  \n",
    "   \n",
    " # summarize history for accuracy  \n",
    "   \n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "   \n",
    " # summarize history for loss  \n",
    "   \n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9d12f-82ed-497f-aa65-7e05eaf45ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import keras\n",
    "\n",
    "print(validation_generator.class_indices)\n",
    "inv_classes = validation_generator.class_indices\n",
    "classes = {v: k for k, v in inv_classes.items()}\n",
    "\n",
    "capture_url = \"http://192.168.0.121/capture\"\n",
    "capture_path = tf.keras.utils.get_file(str(uuid.uuid4()), origin=capture_url)\n",
    "# capture_path = \"../datasets/esp32_motor/test/esp32/796c21e8-4fb1-4e98-a221-2eeb305b1fc0.jpg\" \n",
    "\n",
    "print(f'downloaded {capture_path}')\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    capture_path, target_size=(320,480)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "img_array /= 255.\n",
    "\n",
    "# img_array = img_array.reshape((1, img_array.shape[0], img_array.shape[1], img_array.shape[2]))\n",
    "\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "# img_array = preprocess_input(img_array)\n",
    "\n",
    "predictions = cust_model.predict(img_array)\n",
    "\n",
    "print(f'prediction: {predictions}')\n",
    "\n",
    "score = predictions[0]\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "threshold = 0.3\n",
    "if (1 - abs(np.max(score)) >= threshold):\n",
    "    print('This image could not be classified')\n",
    "else:\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.3f} percent confidence.\"\n",
    "        .format(classes[np.argmax(score)], 100 * float(np.max(score)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8f783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cde110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
